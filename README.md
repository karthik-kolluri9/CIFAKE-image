#  CIFAKE-Image-Classification-and-Explainable-Identification-of-AI-Generated-Synthetic-Images


Recentadvancesinsyntheticdatahaveenabledthegenerationofimageswithsuchhighquality
that human beings cannot distinguish the difference between real-life photographs and Artificial Intelligence
(AI) generated images. Given the critical necessity of data reliability and authentication, this article proposes
to enhanceourabilitytorecogniseAI-generatedimagesthroughcomputervision.Initially,asyntheticdataset
is generated that mirrors the ten classes of the already available CIFAR-10 dataset with latent diffusion,
providing a contrasting set of images for comparison to real photographs. The model is capable of generating
complex visual attributes, such as photorealistic reflections in water. The two sets of data present as a binary
classification problem with regard to whether the photograph is real or generated by AI. This study then proposes the
use of a Convolutional Neural Network (CNN) to classify the images into two categories;
Real or Fake. Following hyperparameter tuning and the training of 36 individual network topologies, 
the optimal approach could correctly classify the images with 92.98% accuracy. Finally, 
this study implements explainable AI via Gradient Class Activation Mapping to explore which features within the images are useful
for classification. Interpretation reveals interesting concepts within the image, in particular, noting that the
actual entity itself does not hold useful information for classification; instead, the model focuses on small
visual imperfectionsinthebackgroundoftheimages.Thecompletedatasetengineeredforthisstudy,referred
to as the CIFAKE dataset, is made publicly available to the research community for future work.

